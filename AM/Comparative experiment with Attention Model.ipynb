{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e74b08f1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Comparative experiment with Attention Model for Solving p-Median"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e55202",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Prepare: Install dependencies\n",
    "### Install with pip\n",
    "* python=3.7\n",
    "* PyTorch>=1.1\n",
    "* numpy\n",
    "* tqdm\n",
    "* cv2\n",
    "* tensorboard_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69c2f4ad",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from utils import torch_load_cpu, load_problem, get_inner_model, move_to\n",
    "from nets.attention_model import AttentionModel\n",
    "from tensorboard_logger import Logger as TbLogger\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a2c875",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## load the settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2134f0c1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(baseline=None, batch_size=10, bl_alpha=0.05, bl_warmup_epochs=0, checkpoint_encoder=False, checkpoint_epochs=1, data_distribution=None, device=device(type='cuda'), embedding_dim=128, epoch_size=50, epoch_start=0, eval_batch_size=10, eval_only=False, exp_beta=0.8, hidden_dim=128, load_path=None, log_dir='logs', log_step=50, lr_critic=0.0001, lr_decay=1, lr_model=0.0001, max_grad_norm=1.0, model='attention', n_encode_layers=3, n_epochs=100, n_facilities=20, n_users=50, no_cuda=False, no_progress_bar=False, no_tensorboard=False, normalization='batch', output_dir='outputs', p=8, problem='PM', r=0.1, resume=None, run_name='20_8_20240903T152832', save_dir='outputs\\\\PM\\\\20_8_20240903T152832', seed=2023, shrink_size=None, tanh_clipping=10.0, use_cuda=True, val_dataset='./data/Test50_20_8.pkl', val_size=10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the run args\n",
    "%run options\n",
    "\n",
    "# Set the random seed\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Optionally configure tensorboard\n",
    "tb_logger = None\n",
    "if not opts.no_tensorboard:\n",
    "    tb_logger = TbLogger(os.path.join(opts.log_dir, \"{}_{}\".format(opts.problem, opts.n_users, opts.n_facilities), opts.run_name))\n",
    "\n",
    "# Set the device\n",
    "use_cuda=True\n",
    "opts.device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "opts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80eb8e99",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Figure out what's the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b4a4bc9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "problems.PM.problem_PM.PM"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem = load_problem(opts.problem)\n",
    "problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418a6256",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Initialize our policy network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e229f45",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttentionModel(\n",
       "  (init_embed): Linear(in_features=2, out_features=128, bias=True)\n",
       "  (init_dynamic): Linear(in_features=1, out_features=32, bias=True)\n",
       "  (l2_dynamic): Linear(in_features=32, out_features=64, bias=True)\n",
       "  (l3_dynamic): Linear(in_features=64, out_features=128, bias=True)\n",
       "  (embedder): GraphAttentionEncoder(\n",
       "    (layers): Sequential(\n",
       "      (0): MultiHeadAttentionLayer(\n",
       "        (0): SkipConnection(\n",
       "          (module): MultiHeadAttention()\n",
       "        )\n",
       "        (1): Normalization(\n",
       "          (normalizer): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): SkipConnection(\n",
       "          (module): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (3): Normalization(\n",
       "          (normalizer): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): MultiHeadAttentionLayer(\n",
       "        (0): SkipConnection(\n",
       "          (module): MultiHeadAttention()\n",
       "        )\n",
       "        (1): Normalization(\n",
       "          (normalizer): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): SkipConnection(\n",
       "          (module): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (3): Normalization(\n",
       "          (normalizer): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): MultiHeadAttentionLayer(\n",
       "        (0): SkipConnection(\n",
       "          (module): MultiHeadAttention()\n",
       "        )\n",
       "        (1): Normalization(\n",
       "          (normalizer): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): SkipConnection(\n",
       "          (module): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (3): Normalization(\n",
       "          (normalizer): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (gru): GRU(128, 128, batch_first=True)\n",
       "  (project_node_embeddings): Linear(in_features=128, out_features=384, bias=False)\n",
       "  (project_fixed_context): Linear(in_features=128, out_features=128, bias=False)\n",
       "  (project_step_context): Linear(in_features=256, out_features=128, bias=False)\n",
       "  (project_out): Linear(in_features=128, out_features=128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_class = {\n",
    "    # 'pointer': PointerNetwork,\n",
    "    'attention': AttentionModel\n",
    "}.get(opts.model, None)\n",
    "\n",
    "assert model_class is not None, \"Unknown model: {}\".format(model_class)\n",
    "model = model_class(\n",
    "    opts.embedding_dim,\n",
    "    opts.hidden_dim,\n",
    "    problem,\n",
    "    n_encode_layers=opts.n_encode_layers,\n",
    "    mask_inner=True,\n",
    "    mask_logits=True,\n",
    "    normalization=opts.normalization,\n",
    "    tanh_clipping=opts.tanh_clipping,\n",
    "    checkpoint_encoder=opts.checkpoint_encoder,\n",
    "    shrink_size=opts.shrink_size,\n",
    "    dy=False\n",
    ").to(opts.device)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c655f036",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## load the AM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "052f95ba",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [*] Loading the trained model from ./output/epoch-99.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opts.load_path = './output/epoch-99.pt'\n",
    "# load model from load_path\n",
    "assert opts.load_path is None or opts.resume is None, \"Only one of load path and resume can be given\"\n",
    "load_path = opts.load_path if opts.load_path is not None else opts.resume\n",
    "if load_path is not None:\n",
    "    print('  [*] Loading the trained model from {}'.format(load_path))\n",
    "    load_data = torch_load_cpu(load_path)\n",
    "\n",
    "# Overwrite model parameters by parameters to load q\n",
    "model_ = get_inner_model(model)\n",
    "model.load_state_dict({**model_.state_dict(), **load_data.get('model', {})})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9fe7ba",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load the real-world datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be4101d1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8228b6fb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### LandScan Population Distribution\n",
    "LandScan data is preprocessed and excluded the regions with no night-time population. Each point in this dataset represents the population aggregated to the centroid of the corresponding grid cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47363bc3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 175 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>经度84</th>\n",
       "      <th>纬度84</th>\n",
       "      <th>POINT_X</th>\n",
       "      <th>POINT_Y</th>\n",
       "      <th>NEAR_FID</th>\n",
       "      <th>NEAR_DIST</th>\n",
       "      <th>NEAR_X</th>\n",
       "      <th>NEAR_Y</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>116.268247</td>\n",
       "      <td>39.970932</td>\n",
       "      <td>950178.402354</td>\n",
       "      <td>4.439620e+06</td>\n",
       "      <td>53</td>\n",
       "      <td>822.227299</td>\n",
       "      <td>950742.699785</td>\n",
       "      <td>4.439022e+06</td>\n",
       "      <td>POINT (950178.402 4439619.552)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>116.278045</td>\n",
       "      <td>39.965943</td>\n",
       "      <td>951048.965144</td>\n",
       "      <td>4.439115e+06</td>\n",
       "      <td>53</td>\n",
       "      <td>320.168328</td>\n",
       "      <td>950742.699785</td>\n",
       "      <td>4.439022e+06</td>\n",
       "      <td>POINT (951048.965 4439114.857)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116.216655</td>\n",
       "      <td>39.996868</td>\n",
       "      <td>945598.585992</td>\n",
       "      <td>4.442241e+06</td>\n",
       "      <td>45</td>\n",
       "      <td>2297.119273</td>\n",
       "      <td>947792.780208</td>\n",
       "      <td>4.442921e+06</td>\n",
       "      <td>POINT (945598.586 4442241.439)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         经度84       纬度84        POINT_X       POINT_Y  NEAR_FID    NEAR_DIST  \\\n",
       "0  116.268247  39.970932  950178.402354  4.439620e+06        53   822.227299   \n",
       "1  116.278045  39.965943  951048.965144  4.439115e+06        53   320.168328   \n",
       "2  116.216655  39.996868  945598.585992  4.442241e+06        45  2297.119273   \n",
       "\n",
       "          NEAR_X        NEAR_Y                        geometry  \n",
       "0  950742.699785  4.439022e+06  POINT (950178.402 4439619.552)  \n",
       "1  950742.699785  4.439022e+06  POINT (951048.965 4439114.857)  \n",
       "2  947792.780208  4.442921e+06  POINT (945598.586 4442241.439)  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ls = gpd.read_file(\"./data/real/haidian_community_pro.shp\")\n",
    "ls['POINT_X'] = ls.geometry.x\n",
    "ls['POINT_Y'] = ls.geometry.y\n",
    "ls.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7b4634",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Candidate Billboard Location\n",
    "Billboards data were retrieved from LAMAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ddc8e87",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>经度84</th>\n",
       "      <th>纬度84</th>\n",
       "      <th>POINT_X</th>\n",
       "      <th>POINT_Y</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>116.257490</td>\n",
       "      <td>40.023362</td>\n",
       "      <td>948914.176201</td>\n",
       "      <td>4.445391e+06</td>\n",
       "      <td>POINT (948914.176 4445390.949)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>116.287560</td>\n",
       "      <td>39.993906</td>\n",
       "      <td>951677.729470</td>\n",
       "      <td>4.442270e+06</td>\n",
       "      <td>POINT (951677.729 4442270.340)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116.353798</td>\n",
       "      <td>39.981356</td>\n",
       "      <td>957422.791546</td>\n",
       "      <td>4.441215e+06</td>\n",
       "      <td>POINT (957422.792 4441214.652)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         经度84       纬度84        POINT_X       POINT_Y  \\\n",
       "0  116.257490  40.023362  948914.176201  4.445391e+06   \n",
       "1  116.287560  39.993906  951677.729470  4.442270e+06   \n",
       "2  116.353798  39.981356  957422.791546  4.441215e+06   \n",
       "\n",
       "                         geometry  \n",
       "0  POINT (948914.176 4445390.949)  \n",
       "1  POINT (951677.729 4442270.340)  \n",
       "2  POINT (957422.792 4441214.652)  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sitedf = gpd.read_file(\"./data/real/haidian_hospital_pro.shp\")\n",
    "sitedf['POINT_X'] = sitedf.geometry.x\n",
    "sitedf['POINT_Y'] = sitedf.geometry.y\n",
    "# sites = np.array(sitedf[['NORM_X', 'NORM_Y']], dtype=np.float64)\n",
    "# print(\"The number of billboards in Seattle area is \", len(sitedf))\n",
    "sitedf.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a40bdc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3d31da9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def Normalization(x, y):\n",
    "    max_x, max_y = np.max(x), np.max(y)\n",
    "    min_x, min_y = np.min(x), np.min(y)\n",
    "    S_x = (max_x-min_x)\n",
    "    S_y = (max_y-min_y)\n",
    "    S = max(S_x, S_y)\n",
    "    new_x, new_y = (x-min_x)/S, (y-min_y)/S\n",
    "    data_xy = np.vstack((new_x, new_y))\n",
    "    Data = data_xy.T\n",
    "    return new_x, new_y, S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0354edfa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ls_X = np.array(ls['POINT_X'])\n",
    "ls_Y = np.array(ls['POINT_Y'])\n",
    "bbs_X = np.array(sitedf['POINT_X'])\n",
    "bbs_Y = np.array(sitedf['POINT_Y'])\n",
    "X = np.concatenate([ls_X, bbs_X])\n",
    "Y = np.concatenate([ls_Y, bbs_Y])\n",
    "NORM_X, NORM_Y, S = Normalization(X, Y)\n",
    "ls['NORM_X'] = NORM_X[:len(ls)]\n",
    "ls['NORM_Y'] = NORM_Y[:len(ls)]\n",
    "sitedf['NORM_X'] = NORM_X[len(ls):]\n",
    "sitedf['NORM_Y'] = NORM_Y[len(ls):]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62870515",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# LandScan sites =1109, Billboard sites=839, R=2000 M=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b0f0a7d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def gen_real_data(ls, num_sample):\n",
    "    real_datasets = []\n",
    "    for i in range(num_sample):\n",
    "        bbs_ = sitedf\n",
    "        real_data = {}\n",
    "        real_data[\"users\"] = torch.tensor(np.array(ls[['NORM_X', 'NORM_Y']])).to(torch.float32)\n",
    "        real_data[\"facilities\"] = torch.tensor(np.array(bbs_[['NORM_X', 'NORM_Y']])).to(torch.float32)\n",
    "        real_data[\"p\"] = 15\n",
    "        real_data[\"r\"] = 2000/S\n",
    "        real_datasets.append(real_data)\n",
    "    return bbs_, real_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18c975bc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_sample = 1\n",
    "opts.eval_batch_size = 10\n",
    "opts.max_calc_batch_size = 1280000\n",
    "width = 1280\n",
    "bbs_, real_datasets = gen_real_data(ls, num_sample)\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "opts.decode_strategy = 'sampling'\n",
    "model.eval()\n",
    "model.set_decode_type(\n",
    "    \"greedy\" if opts.decode_strategy in ('bs', 'greedy') else \"sampling\")\n",
    "dataloader = DataLoader(real_datasets, batch_size=opts.eval_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8990d59a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Greedy strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0347cab",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_best(sequences, cost, ids=None, batch_size=None):\n",
    "    \"\"\"\n",
    "    Ids contains [0, 0, 0, 1, 1, 2, ..., n, n, n] if 3 solutions found for 0th instance, 2 for 1st, etc\n",
    "    :param sequences:\n",
    "    :param lengths:\n",
    "    :param ids:\n",
    "    :return: list with n sequences and list with n lengths of solutions\n",
    "    \"\"\"\n",
    "    if ids is None:\n",
    "        idx = cost.argmin()\n",
    "        return sequences[idx:idx+1, ...], cost[idx:idx+1, ...]\n",
    "\n",
    "    splits = np.hstack([0, np.where(ids[:-1] != ids[1:])[0] + 1])\n",
    "    mincosts = np.minimum.reduceat(cost, splits)\n",
    "\n",
    "    group_lengths = np.diff(np.hstack([splits, len(ids)]))\n",
    "    all_argmin = np.flatnonzero(np.repeat(mincosts, group_lengths) == cost)\n",
    "    result = np.full(len(group_lengths) if batch_size is None else batch_size, -1, dtype=int)\n",
    "\n",
    "    result[ids[all_argmin[::-1]]] = all_argmin[::-1]\n",
    "\n",
    "    return [sequences[i] if i >= 0 else None for i in result], [cost[i] if i >= 0 else math.inf for i in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f369ce49",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The objective of MCBLP by AM is: 157.9359588623047\n",
      "The running time of DRL is: 0.45799875259399414\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "results = []\n",
    "for batch in tqdm(dataloader, disable=True):\n",
    "    batch = move_to(batch, opts.device)\n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        if opts.decode_strategy in ('sampling', 'greedy'):\n",
    "            if opts.decode_strategy == 'greedy':\n",
    "                assert width == 0, \"Do not set width when using greedy\"\n",
    "                assert opts.eval_batch_size <= opts.max_calc_batch_size, \\\n",
    "                    \"eval_batch_size should be smaller than calc batch size\"\n",
    "                batch_rep = 1\n",
    "                iter_rep = 1\n",
    "            elif width * opts.eval_batch_size > opts.max_calc_batch_size:\n",
    "                assert opts.eval_batch_size == 1\n",
    "                assert width % opts.max_calc_batch_size == 0\n",
    "                batch_rep = opts.max_calc_batch_size\n",
    "                iter_rep = width // opts.max_calc_batch_size\n",
    "            else:\n",
    "                batch_rep = width\n",
    "                iter_rep = 1\n",
    "            assert batch_rep > 0\n",
    "            # This returns (batch_size, iter_rep shape)\n",
    "\n",
    "            sequences, costs = model.sample_many(batch, batch_rep=batch_rep, iter_rep=iter_rep)\n",
    "            batch_size = len(costs)\n",
    "            ids = torch.arange(batch_size, dtype=torch.int64, device=costs.device)\n",
    "#         else:\n",
    "#             # assert opts.decode_strategy == 'bs'\n",
    "\n",
    "#             cum_log_p, sequences, costs, ids, batch_size = model.beam_search(\n",
    "#                 batch, beam_size=width,\n",
    "#                 compress_mask=opts.compress_mask,\n",
    "#                 max_calc_batch_size=opts.max_calc_batch_size\n",
    "#             )\n",
    "            if sequences is None:\n",
    "                sequences = [None] * batch_size\n",
    "                costs = [math.inf] * batch_size\n",
    "            else:\n",
    "                sequences, costs = get_best(\n",
    "                    sequences.cpu().numpy(), costs.cpu().numpy(),\n",
    "                    ids.cpu().numpy() if ids is not None else None,\n",
    "                    batch_size\n",
    "                )\n",
    "            duration = time.time() - start\n",
    "            for seq, cost in zip(sequences, costs):\n",
    "                seq = seq.tolist()\n",
    "                results.append((cost, seq, duration))\n",
    "costs, tours, durations = zip(*results)\n",
    "print(f\"The objective of MCBLP by AM is: {costs[0]}\")\n",
    "end = time.time()-start \n",
    "print(f\"The running time of DRL is: {end}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "945d1296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([26, 74, 64, 19, 14, 45, 17, 24, 42, 49, 76, 18, 30, 51, 47],)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729bf2f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
